{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Flora'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier  #RF algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train = pd.read_csv('F:\\second_term\\ADS\\proj3\\Train.csv')\n",
    "test = pd.read_csv('F:\\second_term\\ADS\\proj3\\Test.csv')\n",
    "target = 'y' #this is y\n",
    "IDcol = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Functions for building the model\n",
    "def modelfit(alg, dtrain, dtest, predictors, performCV=True, printFeatureImportance=True, cv_folds=5):\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['y'])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    #dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    dtest_predictions = alg.predict(dtest[predictors])\n",
    "    \n",
    "    #Perform cross-validation:\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg, dtrain[predictors], dtrain['y'], cv=cv_folds, scoring='roc_auc')\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy(train): %.4g\" % metrics.accuracy_score(dtrain['y'].values, dtrain_predictions))\n",
    "    print (\"Accuracy(test) : %.4g\" % metrics.accuracy_score(dtest['y'].values, dtest_predictions))\n",
    "    #print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['y'], dtrain_predprob))\n",
    "    \n",
    "    if performCV:\n",
    "        print (\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-33-cc508239d9e2>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-cc508239d9e2>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    rf0 = BaggingClassifier(base_estimator=None, n_estimators=32, max_samples=1.0,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "#initial estimates:\n",
    "#min_samples_split = 200 : This should be ~0.5-1% of total values.\n",
    "#min_samples_leaf = 50 : Can be selected based on intuition. This is just used for preventing overfitting and again a small value because of imbalanced classes.\n",
    "#max_depth = 1 : for decision stump\n",
    "#max_features = ‘sqrt’ : Its a general thumb-rule to start with square root.\n",
    "#subsample = 0.8 : This is a commonly-used start value\n",
    "#n_estimators=100 : Can be selected based on intuition.\n",
    "#max_features= \"sqrt\": typical sqrt to 30-40% of total features\n",
    "\n",
    "#This is the untuned baseline, the parameters are not necesarily the best.\n",
    "for a in range(28,35):\n",
    "    rf0 = BaggingClassifier(base_estimator=None, n_estimators=a, max_samples=1.0, \n",
    "                        max_features=1.0, bootstrap=True, bootstrap_features=False,\n",
    "                        oob_score=False, warm_start=False, n_jobs=1, random_state=10, verbose=0)\n",
    "    modelfit(rf0, train,test, predictors)#Train: 1 Test:75.5%\n",
    "    print(\"n_tree:%.4g\" % a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy(train): 0.8269\n",
      "Accuracy(test) : 0.6175\n",
      "CV Score : Mean - 0.6257579 | Std - 0.01165835 | Min - 0.6109766 | Max - 0.6445117\n",
      "\n",
      "Model Report\n",
      "Accuracy(train): 0.9038\n",
      "Accuracy(test) : 0.64\n",
      "CV Score : Mean - 0.648436 | Std - 0.02531603 | Min - 0.6184375 | Max - 0.6790234\n",
      "\n",
      "Model Report\n",
      "Accuracy(train): 0.9062\n",
      "Accuracy(test) : 0.685\n",
      "CV Score : Mean - 0.6730063 | Std - 0.02015482 | Min - 0.6503516 | Max - 0.7062891\n",
      "\n",
      "Model Report\n",
      "Accuracy(train): 0.9437\n",
      "Accuracy(test) : 0.7275\n",
      "CV Score : Mean - 0.6904226 | Std - 0.03138707 | Min - 0.6558789 | Max - 0.7495312\n",
      "\n",
      "Model Report\n",
      "Accuracy(train): 0.9431\n",
      "Accuracy(test) : 0.72\n",
      "CV Score : Mean - 0.7053619 | Std - 0.02618655 | Min - 0.6643164 | Max - 0.74375\n",
      "\n",
      "Model Report\n",
      "Accuracy(train): 0.9663\n",
      "Accuracy(test) : 0.7325\n",
      "CV Score : Mean - 0.7192535 | Std - 0.02836114 | Min - 0.6700977 | Max - 0.7548633\n"
     ]
    }
   ],
   "source": [
    "for a in range(2,8):\n",
    "    rf0 = BaggingClassifier(base_estimator=None, n_estimators=a, max_samples=0.8, \n",
    "                        max_features=0.45, bootstrap=True, bootstrap_features=False,\n",
    "                        oob_score=False, warm_start=False, n_jobs=1, random_state=10, verbose=0)\n",
    "    modelfit(rf0, train,test, predictors)#Train: 1 Test:76.75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy(train): 0.86\n",
      "Accuracy(test) : 0.725\n",
      "CV Score : Mean - 0.7459878 | Std - 0.02094646 | Min - 0.7242624 | Max - 0.7837109\n"
     ]
    }
   ],
   "source": [
    "rf0 = BaggingClassifier(base_estimator=None, n_estimators=9, max_samples=0.3,\n",
    "                        max_features=0.8, bootstrap=True, bootstrap_features=False,\n",
    "                        oob_score=False, warm_start=False, n_jobs=1, \n",
    "                        random_state=20, verbose=0)\n",
    "modelfit(rf0, train,test, predictors)#Train: 86% Test:72.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tuned parameter:\n",
    "#base_estimator=None, n_estimators=9, max_samples=0.3,max_features=0.8, bootstrap=True, bootstrap_features=False,\n",
    "#oob_score=False, warm_start=False, n_jobs=1, random_state=20, verbose=0"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
